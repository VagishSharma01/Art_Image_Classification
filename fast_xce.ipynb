{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using image_dataset_from_directory()\n",
    "data_dir = \"D:\\Z\\Data_Set\\Pencil shading (2)\"\n",
    "image_size = (224, 224)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3062 files belonging to 5 classes.\n",
      "Using 2450 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,  # 80% training, 20% validation\n",
    "    subset='training',\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3062 files belonging to 5 classes.\n",
      "Using 612 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the data pipeline\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageDataGenerator for data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Apply data augmentation to the training dataset\n",
    "train_data = train_data.map(lambda x, y: (data_augmentation(x, training=True), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets using sklearn\n",
    "X = []\n",
    "y = []\n",
    "for images, labels in train_data:\n",
    "    X.append(images.numpy())\n",
    "    y.append(labels.numpy())\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Xception model\n",
    "base_model = Xception(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(image_size[0], image_size[1], 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model layers\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom classification head\n",
    "inputs = tf.keras.Input(shape=(image_size[0], image_size[1], 3))\n",
    "x = tf.keras.applications.xception.preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "98/98 [==============================] - 29s 179ms/step - loss: 1.1875 - accuracy: 0.5974 - val_loss: 1.1789 - val_accuracy: 0.5694\n",
      "Epoch 2/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 1.1123 - accuracy: 0.6020 - val_loss: 1.1133 - val_accuracy: 0.5694\n",
      "Epoch 3/25\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 1.0549 - accuracy: 0.6163 - val_loss: 1.0562 - val_accuracy: 0.6000\n",
      "Epoch 4/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.9947 - accuracy: 0.6577 - val_loss: 1.0122 - val_accuracy: 0.6653\n",
      "Epoch 5/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.9549 - accuracy: 0.6847 - val_loss: 0.9858 - val_accuracy: 0.6592\n",
      "Epoch 6/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.9235 - accuracy: 0.6939 - val_loss: 0.9355 - val_accuracy: 0.6735\n",
      "Epoch 7/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.8952 - accuracy: 0.6974 - val_loss: 0.9157 - val_accuracy: 0.6837\n",
      "Epoch 8/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.8730 - accuracy: 0.7000 - val_loss: 0.9181 - val_accuracy: 0.6592\n",
      "Epoch 9/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.8509 - accuracy: 0.7133 - val_loss: 0.8906 - val_accuracy: 0.6878\n",
      "Epoch 10/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.8431 - accuracy: 0.7066 - val_loss: 0.8895 - val_accuracy: 0.6816\n",
      "Epoch 11/25\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 0.8205 - accuracy: 0.7184 - val_loss: 0.8501 - val_accuracy: 0.6980\n",
      "Epoch 12/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.8067 - accuracy: 0.7270 - val_loss: 0.8854 - val_accuracy: 0.6735\n",
      "Epoch 13/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.8023 - accuracy: 0.7235 - val_loss: 0.8268 - val_accuracy: 0.7102\n",
      "Epoch 14/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.7878 - accuracy: 0.7337 - val_loss: 0.8556 - val_accuracy: 0.7041\n",
      "Epoch 15/25\n",
      "98/98 [==============================] - 16s 163ms/step - loss: 0.7782 - accuracy: 0.7301 - val_loss: 0.8204 - val_accuracy: 0.7143\n",
      "Epoch 16/25\n",
      "98/98 [==============================] - 16s 162ms/step - loss: 0.7645 - accuracy: 0.7352 - val_loss: 0.7989 - val_accuracy: 0.7143\n",
      "Epoch 17/25\n",
      "98/98 [==============================] - 16s 161ms/step - loss: 0.7621 - accuracy: 0.7408 - val_loss: 0.8060 - val_accuracy: 0.7041\n",
      "Epoch 18/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.7540 - accuracy: 0.7403 - val_loss: 0.8041 - val_accuracy: 0.6939\n",
      "Epoch 19/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.7541 - accuracy: 0.7367 - val_loss: 0.7917 - val_accuracy: 0.7245\n",
      "Epoch 20/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.7497 - accuracy: 0.7398 - val_loss: 0.7830 - val_accuracy: 0.7204\n",
      "Epoch 21/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.7347 - accuracy: 0.7439 - val_loss: 0.8349 - val_accuracy: 0.6898\n",
      "Epoch 22/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.7342 - accuracy: 0.7429 - val_loss: 0.7994 - val_accuracy: 0.7122\n",
      "Epoch 23/25\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 0.7225 - accuracy: 0.7505 - val_loss: 0.7684 - val_accuracy: 0.7041\n",
      "Epoch 24/25\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 0.7331 - accuracy: 0.7454 - val_loss: 0.7849 - val_accuracy: 0.7041\n",
      "Epoch 25/25\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.7172 - accuracy: 0.7541 - val_loss: 0.7512 - val_accuracy: 0.7102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5d578cb50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 25\n",
    "batch_size = 20\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('xception_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
